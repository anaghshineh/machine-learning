{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip_extension allows for placement of %%skip True at cell beginnings to skip cell execution, even if cell is \"run\"\n",
    "%load_ext skip_extension\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description & Hypothesis\n",
    "\n",
    "This notebook uses the [Yelp Dataset](https://www.yelp.com/dataset/challenge) to explore how the language used in restaurant reviews can be potentially used to classify the price range of the restaurants under review. Restaurants on Yelp oftentimes have a number of \\\\$ signs associated with them, indicating the approximate price per person for the restaurants. This price range attribute runs from 1 to 4 (\\\\$-\\\\$\\\\$\\\\$\\\\$), with 1 representing a cost of < \\\\$10, 2 representing a cost of \\\\$11-\\\\$30, 3 representing a cost of \\\\$31-\\\\$60, and 4 representing a cost of > \\\\$61.\n",
    "\n",
    "In other words, this notebook hypothesizes that the language used in reviews for restaurants of lower price ranges differs from that used in reviews for restaurants of higher price ranges. Reviewers may describe their experiences at pricier restaurants differently than they do for less pricey restaurants.\n",
    "\n",
    "**Hypothesis**: Lexical features extracted from restaurant reviews can provide information that allows for the differentiation between reviews on restaurants of different price ranges. These features can be used to classify the price range of the restaurant being reviewed.\n",
    "\n",
    "**Sub-hypothesis**: Furthermore, controlling for star rating of the review can help improve classification power, as the model will try to find patterns based more on price range-specific language and not sentiment-specific (as reflected by the star rating assigned). For example, it will better be able to discern between a 4-star review for a \\\\$ restaurant and a 4-star review for a \\\\$$$ restaurant.\n",
    "\n",
    "A defining feature of this notebook is its heavy usage of interactive controls, [```ipywidgets```](https://ipywidgets.readthedocs.io/en/latest/), for data exploration and modeling. In many cases, cells will contain numerous capabilities and customization options through their various widgets. Given the size of the dataset and the computational burden associated with generating certain visualizations of this data, several visualizations generated throughout the process of this project are embedded within the notebook itself. There are also interactive code blocks that allow you to scroll through multiple visualizations generated by the same code block (pulling from the figures folder of this repository). The visualization code is always provided for those who would like to reproduce the visualizations, and all original figures are in the ```figures``` folder of this repository.\n",
    "\n",
    "The raw data contains 6,685,900 reviews and 192,609 unique businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Label Remappings\n",
    "The default class labels used in this notebook are the price ranges 1, 2, 3, and 4. However, several different remappings of the class labels were also explored to see how model performance was impacted. In addition to the default labeling scheme, three other labeling schemes were explored for a total of four:\n",
    "1. **Default**: This labeling scheme took the price ranges as they are and used them as the target classes. \n",
    "2. **[1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$]**: This labeling scheme bifurcated the price ranges, grouping the two lower ranges, 1\\\\$ and 2\\\\$, together, and the two higher ranges, 3\\\\$ and 4\\\\$, together.\n",
    "3. **[1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$] > [1\\*-3\\*] vs. [4\\*-5\\*]**: This remapping scheme creates four classes. The first class is reviews on restaurants in the price ranges 1\\\\$ and 2\\\\$ with star ratings of one to three stars (1\\* to 3\\*). The second class is for reviews on restaurants in the same lower price ranges but with star ratings of four or five stars (4\\* to 5\\*). The third and fourth classes are similar to these two, but they involve the higher two price ranges, 3\\\\$ and 4\\\\$.\n",
    "4. **[1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$] > [1\\*-2\\*] vs. [4\\*-5\\*]**: This remapping scheme is very similar to the one above, but it removes reviews with a star rating of three (3\\*) from consideration. It still creates four classes, but the two classes that previously contained reviews with star ratings from one to three stars (1\\* to 3\\*) now only contain reviews with star ratings of one or two stars (1\\* to 2\\*). Although this relabeling scheme results in lost data compared with the other schemes, it does remove noisy three-star reviews from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "This notebook utilizes the [Yelp Dataset](https://www.yelp.com/dataset/challenge) that is publicly available for download to researchers and academics. Although publicly available, the dataset comes with limitations regarding its distribution under the *Yelp Dataset Terms of Use*. Therefore, the data necessary for executing this notebook is not stored publicly in the repository associated with this notebook. If you would like to replicate the steps in this notebook, please download the dataset from the aforementioned link.\n",
    "\n",
    "The dataset is split between five JSON files: \n",
    "- ```business.json```, which provides information on the businesses in the dataset (e.g., location, name, category)\n",
    "- ```review.json```, which has the text reviews, the review start ratings, and other review-related information\n",
    "- ```user.json```, which contains user/reviewer-related metadata\n",
    "- ```checkin.json```, which provides data on the various checkins at the businesses\n",
    "- ```tip.json```, which contains the tip text written by users\n",
    "\n",
    "Given the focus of the hypothesis, this notebook only makes use of the ```business.json``` and ```review.json``` data. The ```user.json``` data was also ingested for future exploration of user metadata, but this data was not used in this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "\n",
    "The Yelp dataset was stored locally using PostgreSQL. Custom Python scripts were used to extract the data from the JSON files and load it into the database. Below, custom modules, ```Yelp_DB_Maker``` and ```Yelp_Data_Importer``` are imported and used for data ingestion. The scripts containing these modules are included along with this notebook in the repository for ease of reproduction. Following the **Imports** cell below, you will need to enter your PostgreSQL credentials along with the path to where you have locally stored the Yelp data. The default database name for holding the data is set to 'yelp,' but feel free to change this whatever name you like. The data ingestion code includes progress/loading bars to keep you apprised of ingestion progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import Yelp_DB_Maker\n",
    "import Yelp_Data_Importer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'yelp2'\n",
    "username = 'postgres'\n",
    "password = 'KhobDige12!'\n",
    "dataset_path = '/Users/alice.naghshineh/Desktop/yelp_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect('dbname={} user={} password={}'.format(dbname, username, password))\n",
    "    conn.set_session(autocommit=True)\n",
    "    print('Connection to database established.')\n",
    "\n",
    "except psycopg2.Error:\n",
    "    print('Database does not exist. Creating database now.')\n",
    "    conn = psycopg2.connect('dbname={} user={} password={}'.format('postgres', username, password))\n",
    "    cur = conn.cursor()\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur.execute('CREATE DATABASE {}'.format(dbname))\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    conn = psycopg2.connect('dbname={} user={} password={}'.format(dbname, username, password))\n",
    "    print('Database created.')\n",
    "    conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = []\n",
    "for file in os.listdir(dataset_path):\n",
    "    if len(file.split('.')) >= 2 and file.split('.')[-1].lower() == 'json':\n",
    "        datafiles.append(file)\n",
    "\n",
    "print('Available Data Files:\\n')\n",
    "for file in datafiles:\n",
    "    print('\\t' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yelp_DB_Maker.YelpDBMaker(conn, datafiles).create()\n",
    "Yelp_Data_Importer.YelpDataImporter(conn, datafiles, dataset_path).populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    SELECT business.business_id, categories, business.stars, price_range, review.review_id, review.stars, review_text, user_info.user_id, elite, average_stars\n",
    "    FROM business JOIN review ON business.business_id = review.business_id JOIN user_info ON review.user_id = user_info.user_id\n",
    "\"\"\")\n",
    "\n",
    "cols = ['business_id', 'categories', 'business_stars', 'price_range', 'review_id', 'review_stars',\n",
    "        'review_text', 'user_id', 'elite', 'user_average_stars']\n",
    "\n",
    "data = pd.DataFrame(cur.fetchall(), columns=cols)\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip True\n",
    "with open(os.path.join(dataset_path, 'raw_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip True\n",
    "#Load the dataframe from pickle file\n",
    "with open(os.path.join(dataset_path, 'raw_data.pkl'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data for Further Exploration\n",
    "Arguably, text data requires more purposeful \"cleaning\" than many other kinds of data (e.g., numerical). Raw text cannot be fed into models; it must be vectorized, or given a mathematical representation with which the model can make sense. This section of the notebook is devoted to preparing the text data for modeling and to cleaning the data in other ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Review Text\n",
    "\n",
    "The text preprocessing for this project largely relies on [```NLTK```](https://www.nltk.org). Generic English stopwords are removed, although the preprocessing code purposefully retains what are typically treated as stopwords but convey negativity (e.g., don't, not, but, won't, etc.). These words are likely important for capturing the sentiment of reviews and are therefore retained. The preprocessing code below tokenizes the data and allows for the option of also lemmatizing the tokens. In the context of this project, distinct data columns containing non-lemmatized tokens and lemmatized tokens were created to compare the effect of lemmatization on model performance.\n",
    "\n",
    "Given that preprocessing so many reviews is time intensive, progress/loading bars are built into the code. It is recommended that the tokenized data be pickled after completion of the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & NLTK Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alice.naghshineh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alice.naghshineh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alice.naghshineh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpPreProcess():\n",
    "    \n",
    "    def __init__(self, df, lemmatize=False, tokenize=True):\n",
    "        self.df = df\n",
    "        self.tokenize = tokenize\n",
    "        self.lem = lemmatize\n",
    "        \n",
    "    def create_stop_words(self):\n",
    "        stops = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        neg_stops = [\n",
    "            'no', 'nor', 'not', 'don', \"don't\",\n",
    "            'ain', 'aren', \"aren't\", 'couldn',\n",
    "            \"couldn't\", 'didn', \"didn't\", 'doesn',\n",
    "            \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
    "            \"hasn't\", 'haven', \"haven't\", 'isn',\n",
    "            \"isn't\", 'mightn', \"mightn't\", 'mustn',\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan',\n",
    "            \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "            \"wasn't\", 'weren', \"weren't\", \"won'\",\n",
    "            \"won't\", 'wouldn', \"wouldn't\", 'but',\n",
    "            \"don'\", \"ain't\"\n",
    "        ]\n",
    "\n",
    "        common_nonneg_contr = [\n",
    "            \"could've\", \"he'd\", \"he'd've\", \"he'll\",\n",
    "            \"he's\", \"how'd\", \"how'll\", \"how's\",\n",
    "            \"i'd\", \"i'd've\", \"i'll\", \"i'm\",\n",
    "            \"i've\", \"it'd\", \"it'd've\", \"it'll\",\n",
    "            \"it's\", \"let's\", \"ma'am\", \"might've\",\n",
    "            \"must've\", \"o'clock\", \"'ow's'at\",\n",
    "            \"she'd\", \"she'd've\", \"she'll\", \"she's\",\n",
    "            \"should've\", \"somebody'd\", \"somebody'd've\",\n",
    "            \"somebody'll\", \"somebody's\", \"someone'd\",\n",
    "            \"someone'd've\", \"someone'll\", \"someone's\",\n",
    "            \"something'd\", \"something'd've\", \"something'll\",\n",
    "            \"something's\", \"that'll\", \"that's\", \"there'd\",\n",
    "            \"there'd've\", \"there're\", \"there's\", \"they'd\",\n",
    "            \"they'd've\", \"they'll\", \"they're\", \"they've\",\n",
    "            \"'twas\", \"we'd\", \"we'd've\", \"we'll\",\n",
    "            \"we're\", \"we've\", \"what'll\", \"what're\",\n",
    "            \"what's\", \"what've\", \"when's\", \"where'd\",\n",
    "            \"where's\", \"where've\", \"who'd\", \"who'd've\",\n",
    "            \"who'll\", \"who're\", \"who's\", \"who've\",\n",
    "            \"why'll\", \"why're\", \"why's\", \"would've\",\n",
    "            \"y'all\", \"y'all'll\", \"y'all'd've\", \"you'd\",\n",
    "            \"you'd've\", \"you'll\", \"you're\", \"you've\"\n",
    "        ]\n",
    "\n",
    "        letters = [\n",
    "            'a', 'b', 'c', 'd', 'e', 'f', \n",
    "            'g', 'h', 'i', 'j', 'k', 'l', \n",
    "            'm', 'n', 'o', 'p', 'q', 'r', \n",
    "            's', 't', 'u', 'v', 'w', 'x', \n",
    "            'y', 'z'\n",
    "        ]\n",
    "\n",
    "        ranks = ['st', 'nd', 'rd', 'th']\n",
    "\n",
    "        #Make sure negative words are not being retained in the original stops list\n",
    "        stops = [x for x in stops if x not in neg_stops]\n",
    "\n",
    "        stops = stops + common_nonneg_contr + letters + ranks + [\"\"] + ['us'] + [''] + [\"'\"] + [\"'s\"]\n",
    "        stops = list(set(stops))\n",
    "        return stops\n",
    "    \n",
    "    def clean_and_tokenize(self, text):\n",
    "        text = text.lower()\n",
    "        tokenizer = nltk.RegexpTokenizer('\\w+\\'?\\w+')\n",
    "        filtered_tokens = [(re.sub(r\"[^A-Za-z']\", '', token)) for token in tokenizer.tokenize(text)]\n",
    "        stops = self.create_stop_words()\n",
    "        tokens = [token for token in filtered_tokens if token not in stops]\n",
    "        tokens = [re.sub(\"'s\", '', token) for token in tokens]\n",
    "        return tokens\n",
    "        \n",
    "               \n",
    "    def wordnet_lemmatize(self, tokens_list):\n",
    "        wnl = nltk.WordNetLemmatizer()\n",
    "        tag_dict = {\"a\": wordnet.ADJ,\n",
    "                    \"n\": wordnet.NOUN,\n",
    "                    \"v\": wordnet.VERB,\n",
    "                    \"r\": wordnet.ADV}\n",
    "        tokens = [wnl.lemmatize(token, pos=tag_dict.get(nltk.pos_tag([token])[0][1][0].lower(), wordnet.NOUN)) \n",
    "                  for token in tokens_list]\n",
    "        return tokens        \n",
    "    \n",
    "    def process_text(self):\n",
    "        if self.tokenize:\n",
    "            tqdm_notebook.pandas(desc='Tokenization Progress')\n",
    "            self.df['review_tokens'] = self.df['review_text'].progress_apply(lambda x: self.clean_and_tokenize(x))\n",
    "        if self.lem:\n",
    "            tqdm_notebook.pandas(desc='Lemmatization Progress')\n",
    "            self.df['lemmatized_tokens'] = self.df['review_tokens'].progress_apply(lambda x: self.wordnet_lemmatize(x))\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = YelpPreProcess(df=data, tokenize=True, lemmatize=True).process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make sure the tokenization process worked properly by observing a subset of the new dataframe.\n",
    "for i in np.random.randint(low=1, high=1000, size=3):\n",
    "    print('Original review text:\\n')\n",
    "    print(data.loc[i, 'review_text'])\n",
    "    print('\\n')\n",
    "    print('Review tokens:\\n')\n",
    "    print(data.loc[i, 'review_tokens'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Cleaning & Feature Engineering\n",
    "\n",
    "This section accomplishes several goals towards finalizing the dataset for modeling:\n",
    "\n",
    "- **Remove non-English reviews**: Unfortunately, the Yelp dataset contains thousands of non-English text reviews. These non-English reviews make up a small fraction of the total reviews, but they are filtered out to focus on English reviews only. This filtering process relies on the [```langid.py```](https://github.com/saffsd/langid.py) language identification tool to identify the language of the reviews. Only those receiving a classification of 'en' were retained.\n",
    "- **Create restaurant dummy variable**: Althought the Yelp dataset contains reviews on businesses of various categories, the large majority of reviews are on restaurants. To control for the potentially confounding effect of business category on the language used in the reviews and also business category's possible correlation with price range, the analysis in this notebook is eventually limited to restaurants only. Non-restaurants are removed from the analysis later in the notebook, but they are initially retained for visualization purposes. This dummy variable allows for their easy removal later. To create it, businesses with 'categories' text containing 'Restaurants,' indicating that they are restaurants (potentially among other categorizations), were marked with a 1 and 0 otherwise.\n",
    "- **Construct variables for estimated review length and tokens count**: This notebook also explores the possibility that review length (also measured through the count of tokens in the review after tokenization) is associated with the reviewed businesses' price ranges. Do pricier/fancier restaurants tend to receive, on average, longer reviews?\n",
    "- **Filter out reviews on restaurants without price range data**: Seeing as this notebook seeks to classify the price ranages of businesses under review, those reviews on businesses without recorded price range data are removed from consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path, 'tokenized_data.pkl'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['categories'].fillna('', inplace = True)\n",
    "data['is_restaurant'] = [1 if 'Restaurants' in x else 0 for x in data['categories']]\n",
    "data['est_review_len'] = data['review_text'].apply(lambda x: len(x.split()))\n",
    "data['tokens_len'] = data['review_tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas(desc=\"Language Detection Progress\")\n",
    "data['language_detected'] = data['review_text'].progress_apply(lambda x: langid.classify(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts = dict(data['language_detected'].value_counts())\n",
    "print('# of reviews classified as non-English: {}'.format(len(data)-language_counts['en']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['language_detected'] == 'en']\n",
    "data = data[data['price_range'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Visualizations\n",
    "\n",
    "This section of the notebook is dedicated to exploring the data largely through visualizations. The first sub-section provides code for visualizations that rely on libraries outside of ```Yellowbrick```. The second sub-section utilizies several different ```Yellowbrick``` visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Yellowbrick\n",
    "\n",
    "In this sub-section, you will find code that generates multiple visualizations, including an interactive set of bar graphs, several graphs looking at the relationship between review length, price ranges, and review ratings, wordclouds, and a scatterplot capturing and confirming the high correlation between review length and review token count (this high correlation was used as justification later for including token count alone as a feature). The second to last code block is interactive and generates the top unigrams and bigrams (based on TF-IDF Vectorization) that are correlated with the different class labels and their remappings. The section ends with a visualization looking at the problem of class imbalance within each of the four label remappings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, Layout\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "import collections\n",
    "from wordcloud import WordCloud\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```dummy_fun``` function below is used multiple times throughout this notebook. It is primarily used within the text vectorizers to ensure that they do not perform any preprocessing (i.e., tokenization, stop word removel, etc.) on the already tokenized review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_bar(column=['price_range', 'review_stars', \n",
    "                     'categories', 'price_range -groupby- review_stars', \n",
    "                     'review_stars -groupby- price_range', 'price_range -groupby- categories']):\n",
    "    \n",
    "    if column in ['price_range', 'review_stars', 'categories']:\n",
    "        if column == 'price_range':\n",
    "            filtered_data = dict(data[column].value_counts())\n",
    "            labels_dict = {k:'{}$'.format(k) for k in list(filtered_data.keys())}\n",
    "            ticktext= list(labels_dict.values())\n",
    "            title_text = 'Price_Range'\n",
    "\n",
    "        if column == 'review_stars':\n",
    "            filtered_data = dict(data.loc[data['price_range'].notnull()][column].value_counts())\n",
    "            labels_dict = {k:k*'*' for k in list(filtered_data.keys())}\n",
    "            ticktext= list(labels_dict.values())\n",
    "            title_text = 'Review_Stars'\n",
    "\n",
    "        if column == 'categories':\n",
    "            column = 'is_restaurant'\n",
    "            filtered_data = dict(data.loc[data['price_range'].notnull()][column].value_counts())\n",
    "            ticktext = ['Restaurants', 'Non-Restaurants']\n",
    "            title_text = 'Categories'            \n",
    "            column = 'business'\n",
    "        \n",
    "        x = list(filtered_data.keys())\n",
    "        y = list(filtered_data.values())\n",
    "        fig = go.Figure([go.Bar(x=x, y=y, marker={'color':y, 'colorscale': 'haline'})])\n",
    "\n",
    "        fig.update_layout(title_text='{} Counts (for data with non-null price_range values)'.format(title_text),\n",
    "            title_font_size=18,\n",
    "            xaxis = dict(\n",
    "            tickmode = 'array',\n",
    "            tickvals = x,\n",
    "            title = '{} categories'.format(column),\n",
    "            tickfont=dict(size=12),\n",
    "            ticktext=ticktext),\n",
    "            yaxis = dict(\n",
    "            tickmode = 'array',\n",
    "            title = 'count',\n",
    "            tickfont=dict(size=12)\n",
    "            )\n",
    "          )\n",
    "\n",
    "    elif column == 'price_range -groupby- review_stars':\n",
    "        price_ranges = ['1', '2', '3', '4']\n",
    "        filtered_data = list(data.groupby(['price_range', 'review_stars']).size())\n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(name='*', x=price_ranges, y=[filtered_data[i] for i in range(0,20,5)]),\n",
    "            go.Bar(name='**', x=price_ranges, y=[filtered_data[i] for i in range(1,20,5)]),\n",
    "            go.Bar(name='***', x=price_ranges, y=[filtered_data[i] for i in range(2,20,5)]),\n",
    "            go.Bar(name='****', x=price_ranges, y=[filtered_data[i] for i in range(3,20,5)]),\n",
    "            go.Bar(name='*****', x=price_ranges, y=[filtered_data[i] for i in range(4,20,5)])\n",
    "            ])\n",
    "     \n",
    "        fig.update_layout(barmode='stack',\n",
    "                     title_text = 'Price_Range Counts Grouped by by Review_Stars',\n",
    "                     title_font_size = 18,\n",
    "                     xaxis = dict(\n",
    "                     tickmode = 'array',\n",
    "                     tickvals = price_ranges,\n",
    "                     title = 'price_range categories',\n",
    "                     tickfont = dict(size=12),\n",
    "                     ticktext=['1$', '2$', '3$', '4$']),\n",
    "                     yaxis = dict(\n",
    "                     title = 'count',\n",
    "                     tickfont = dict(size=12)))\n",
    "    \n",
    "    elif column == 'review_stars -groupby- price_range':\n",
    "        review_stars = ['1', '2', '3', '4', '5']\n",
    "        filtered_data = list(data.groupby(['review_stars', 'price_range']).size())\n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(name='1$', x=review_stars, y=[filtered_data[i] for i in range(0,20,4)]),\n",
    "            go.Bar(name='2$', x=review_stars, y=[filtered_data[i] for i in range(1,20,4)]),\n",
    "            go.Bar(name='3$', x=review_stars, y=[filtered_data[i] for i in range(2,20,4)]),\n",
    "            go.Bar(name='4$', x=review_stars, y=[filtered_data[i] for i in range(3,20,4)])\n",
    "            ])\n",
    "\n",
    "        fig.update_layout(barmode='stack',\n",
    "                         title_text = 'Review_Stars Counts Grouped by Price_Range',\n",
    "                         title_font_size = 18,\n",
    "                         xaxis = dict(\n",
    "                         tickmode = 'array',\n",
    "                         tickvals = review_stars,\n",
    "                         title = 'review_stars categories',\n",
    "                         tickfont = dict(size=12),\n",
    "                         ticktext = ['*', '**', '***', '****', '*****']),\n",
    "                         yaxis = dict(\n",
    "                         title = 'count',\n",
    "                         tickfont = dict(size=12)))\n",
    "        \n",
    "    else:\n",
    "        filtered_data = list(data.groupby(['price_range', 'is_restaurant']).size())\n",
    "        price_ranges = ['1','2','3','4']\n",
    "        \n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(name='Restaurant', x=price_ranges, y=[filtered_data[i] for i in range(1,8,2)]),\n",
    "            go.Bar(name='Non-Restaurant', x=price_ranges, y=[filtered_data[i] for i in range(0,8,2)])\n",
    "            ])\n",
    "        \n",
    "        fig.update_layout(barmode='stack',\n",
    "                         title_text = 'Price_Range Counts Grouped by Category (Restaurant vs. Non-Restaurant)',\n",
    "                         title_font_size = 18,\n",
    "                         xaxis = dict(\n",
    "                         tickmode = 'array',\n",
    "                         tickvals = price_ranges,\n",
    "                         title = 'price_range categories',\n",
    "                         tickfont = dict(size=12),\n",
    "                         ticktext = ['1$', '2$', '3$', '4$']),\n",
    "                         yaxis = dict(\n",
    "                         title = 'count',\n",
    "                         tickfont = dict(size=12)))        \n",
    "        \n",
    "    fig.show()\n",
    "    \n",
    "interact_manual(plot_bar);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b27ca84c19477fa7cb65a4ade99e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file', options=('review_stars_groupby_price_range_bar.png', 'price…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_bar_plots(file=os.listdir('figures/bar_plots')):\n",
    "    display(Image(os.path.join('figures/bar_plots/', file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data[data['price_range'].notnull()], x='est_review_len')\n",
    "fig.update_layout(title = 'Review Length Histogram (for data with non-null price_range values)',\n",
    "                 xaxis = dict(title='review length'),\n",
    "                 yaxis = dict(title='count'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/review_length_figs/review_length_histogram.png\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "price_ranges = ['1', '2', '3', '4']\n",
    "\n",
    "for price_range in price_ranges:\n",
    "    fig.add_trace(go.Box(x=data['price_range'][data['price_range'] == price_range],\n",
    "                            y=data['est_review_len'][data['price_range'] == price_range],\n",
    "                            name='{}$'.format(price_range)))\n",
    "\n",
    "fig.update_layout(title = 'Review Length Boxplots By Price Range',\n",
    "                 xaxis = dict(showticklabels=False),\n",
    "                 yaxis = dict(title='review length',\n",
    "                             tickfont = dict(size=12)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/review_length_figs/review_length_price_range_boxplots.png\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for price_range in ['1', '2', '3', '4']:\n",
    "    ax = sns.kdeplot(data[data['price_range'] == price_range]['est_review_len'], \n",
    "                     shade=False, label='{}$'.format(price_range))\n",
    "\n",
    "plt.title('Review Length Density Plot for Price Ranges', size=18)\n",
    "plt.xlabel('review length', size=14)\n",
    "plt.ylabel('density', size=14)\n",
    "plt.legend(title ='price_range', fontsize=12, title_fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/review_length_figs/review_length_kdeplot_by_price_range.png\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, sharex=True, sharey=True, figsize=(10,8))\n",
    "for ax, price_range in list(zip(axes.flatten(), ['1','2','3','4'])):\n",
    "    ax.set_xticks([0,250,500,750,1000])\n",
    "    ax.set_title('price_range = {}'.format(price_range+'$'))\n",
    "    for star in [1,2,3,4,5]:\n",
    "        sns.kdeplot(data[(data['price_range'] == price_range) & (data['review_stars'] == star)]['est_review_len'], \n",
    "                  shade=False, ax=ax, label='{}'.format(star*'*'))\n",
    "        \n",
    "fig.suptitle('Review Length Density Plots for Each Price Range Broken Down by Star Rating', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Review Length', ha='center', size=14)\n",
    "fig.text(0.04, 0.5, 'Density', va='center', rotation='vertical', size=14);    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/review_length_figs/review_length_kdeplots_by_price_range_review_stars.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=5000)\n",
    "fig = go.Figure(data=go.Scatter(x=data_sample['est_review_len'],\n",
    "                                y=data_sample['tokens_len'],\n",
    "                                mode='markers',\n",
    "                                marker_color=data_sample['tokens_len'])) \n",
    "\n",
    "fig.update_layout(title='Review Length vs. Token Count',\n",
    "                  xaxis=dict(title='Review Length'),\n",
    "                  yaxis=dict(title='Token Count'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/review_len_token_count_scatter.png\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These two features are highly correlated! They can be used interchangeably within the model.\n",
    "corr, _ = pearsonr(data['est_review_len'], data['tokens_len'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wc(price_range=['1$', '2$', '3$', '4$', 'All Price Ranges'], num_words = (1,1000)):\n",
    "    price_range_dict = {'1$': '1', '2$': '2', '3$': '3', '4$': '4'}\n",
    "    if price_range != 'All Price Ranges':\n",
    "        tokenized_review_list = data[data['price_range'] == price_range_dict[price_range]]['review_tokens'].tolist()\n",
    "    else:\n",
    "        tokenized_review_list = data['review_tokens'].tolist()\n",
    "    tokens_list = [token for tokenized_review in tokenized_review_list for token in tokenized_review]\n",
    "    c = collections.Counter()\n",
    "    c.update(tokens_list)\n",
    "    wc = WordCloud(background_color=\"white\", height=700, width=1000).generate_from_frequencies(dict(c))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    return plt.show()\n",
    "\n",
    "interact_manual(create_wc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121458206161400185c05ca332444edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file', options=('wc_all_price_ranges.png', 'wc_2$.png', 'wc_3$.png…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = [f for f in os.listdir('figures/word_clouds') if f.split('.')[1] == 'png']\n",
    "@interact\n",
    "def show_word_clouds(file=files):\n",
    "    display(Image(os.path.join('figures/word_clouds/', file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlated_grams(token_type = ['Non-Lemmatized', 'Lemmatized'], \n",
    "                          remap_type = ['Default', '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]', \n",
    "                                          '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]']):\n",
    "    \n",
    "    if 'remapped_labels' in data.columns:\n",
    "        data.drop(columns=['remapped_labels'], inplace=True)    \n",
    "    \n",
    "    tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, \n",
    "                            token_pattern=None, ngram_range = (1,2))\n",
    "    \n",
    "    if token_type == 'Non-Lemmatized':\n",
    "        file_name = 'non_lemmatized_correlated_grams_'\n",
    "        tokens = 'review_tokens'\n",
    "    else:\n",
    "        file_name = 'lemmatized_correlated_grams_'\n",
    "        tokens = 'lemmatized_tokens'\n",
    "    \n",
    "    if remap_type == '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':\n",
    "        data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                         (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '1'\n",
    "        data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                         (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "        data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                         (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '3'\n",
    "        data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                         (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'  \n",
    "        file_name += 'remap1.pkl'\n",
    "        \n",
    "    elif remap_type == '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]':\n",
    "        data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                         (data['review_stars'].isin([1,2])), 'remapped_labels'] = '1'\n",
    "        data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                         (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "        data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                         (data['review_stars'].isin([1,2])), 'remapped_labels'] = '3'\n",
    "        data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                         (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "        file_name += 'remap2.pkl' \n",
    "        \n",
    "    else:\n",
    "        data['remapped_labels'] = data['price_range']\n",
    "        file_name += 'default.pkl'\n",
    "        \n",
    "    remapped_data = data[data['remapped_labels'].notnull()]    \n",
    "    features = tfidf.fit_transform(remapped_data[tokens])\n",
    "    corr_grams = pd.DataFrame(columns=['price_range', 'unigrams', 'bigrams'])\n",
    "\n",
    "    class_names_dict = {'Default': {'1':'1$', '2':'2$', '3':'3$', '4':'4$'},\n",
    "                        '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':{'1':'[1$ & 2$] > [1*-3*]',\n",
    "                                                                     '2':'[1$ & 2$] > [4*-5*]',\n",
    "                                                                     '3':'[3$ & 4$] > [1*-3*]',\n",
    "                                                                     '4':'[3$ & 4$] > [4*-5*]'},\n",
    "                        '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]':{'1':'[1$ & 2$] > [1*-2*]',\n",
    "                                                                     '2':'[1$ & 2$] > [4*-5*]',\n",
    "                                                                     '3':'[3$ & 4$] > [1*-2*]',\n",
    "                                                                     '4':'[3$ & 4$] > [4*-5*]'}}\n",
    "    N = 10\n",
    "    for class_label in ['1', '2', '3', '4']:\n",
    "        class_name = class_names_dict[remap_type][class_label]\n",
    "        features_chi2 = chi2(features, labels == class_label)\n",
    "        indices = np.argsort(features_chi2[0])\n",
    "        feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "        unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "        bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "        class_label_row = pd.DataFrame([[class_name, unigrams[-N:], bigrams[-N:]]],\n",
    "                                      columns=['class_name', 'unigrams', 'bigrams'])\n",
    "        corr_grams = corr_grams.append(class_label_row, ignore_index=True)\n",
    "        print(\"Price range {}$\".format(class_name))\n",
    "        print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "        print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))\n",
    "    \n",
    "    with open(os.path.join(dataset_path, file_name), 'wb') as f:\n",
    "        pickle.dump(corr_grams, f)\n",
    "        \n",
    "interact_manual(find_correlated_grams);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def see_correlated_grams(df_file=['non_lemmatized_correlated_grams', 'lemmatized_correlated_grams']):\n",
    "    pd.set_option('max_colwidth', 800)\n",
    "    with open(os.path.join('data/correlated_grams', df_file+'.pkl'), 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, sharex=False, sharey=True, figsize=(13,10))\n",
    "price_range_counts = dict(data['price_range'].value_counts())\n",
    "price_range_stars_counts = list(data.groupby(['price_range', 'review_stars']).size())\n",
    "for ax, remap_type in list(zip(axes.flatten(), ['Default', '[1$ & 2$] vs. [3$ & 4$]',\n",
    "                                                '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]',\n",
    "                                                '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]'])):\n",
    "    \n",
    "    ax.set_title('{}'.format(remap_type))\n",
    "    if remap_type == 'Default':\n",
    "        x = ['1$', '2$', '3$', '4$']\n",
    "        y = [price_range_counts['1'], price_range_counts['2'], price_range_counts['3'], price_range_counts['4']]\n",
    "    elif remap_type == '[1$ & 2$] vs. [3$ & 4$]':\n",
    "        x = ['[1$ & 2$]', '[3$ & 4$]']\n",
    "        y = [price_range_counts['1'] + price_range_counts['2'], price_range_counts['3'] + price_range_counts['4']]\n",
    "    elif remap_type == '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':\n",
    "        x = ['[1$ & 2$] > [1*-3*]', '[1$ & 2$] > [4*-5*]','[3$ & 4$] > [1*-3*]','[3$ & 4$] > [4*-5*]']\n",
    "        y = [sum(price_range_stars_counts[0:3])+sum(price_range_stars_counts[5:8]),\n",
    "             sum(price_range_stars_counts[3:5])+sum(price_range_stars_counts[8:10]),\n",
    "             sum(price_range_stars_counts[10:13])+sum(price_range_stars_counts[15:18]),\n",
    "             sum(price_range_stars_counts[13:15])+sum(price_range_stars_counts[18:20])]\n",
    "    else:\n",
    "        x = ['[1$ & 2$] > [1*-2*]', '[1$ & 2$] > [4*-5*]','[3$ & 4$] > [1*-2*]','[3$ & 4$] > [4*-5*]']\n",
    "        y = [sum(price_range_stars_counts[0:2])+sum(price_range_stars_counts[5:7]),\n",
    "             sum(price_range_stars_counts[3:5])+sum(price_range_stars_counts[8:10]),\n",
    "             sum(price_range_stars_counts[10:12])+sum(price_range_stars_counts[15:17]),\n",
    "             sum(price_range_stars_counts[13:15])+sum(price_range_stars_counts[18:20])]\n",
    "        \n",
    "    sns.barplot(x=x, y=y, ax=ax)\n",
    "    \n",
    "fig.suptitle('Class Imbalance Across Different Label Remappings', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Target Classes', ha='center', size=12)\n",
    "fig.text(0.04, 0.5, 'Count', va='center', rotation='vertical', size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/class_imbalance.png\" width=\"700\" height=\"400\" align='middle'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellowbrick Visualizations\n",
    "\n",
    "The Yellowbrick Visualizations sub-section makes use of three Text Modeling Visualizers from [```Yellowbrick```](https://www.scikit-yb.org/en/latest/index.html).\n",
    "\n",
    "These three Text Modeling Visualizers are:\n",
    "- [Token Frequency Distribution](https://www.scikit-yb.org/en/latest/api/text/freqdist.html)\n",
    "- [t-SNE Corpus Visualization](https://www.scikit-yb.org/en/latest/api/text/tsne.html)\n",
    "- [UMAP Corpus Visualization](https://www.scikit-yb.org/en/latest/api/text/umap_vis.html)\n",
    "\n",
    "The code for the Token Frequency Distribution is interactive and allows you to look at top token counts for all price ranges together and for each price range individually. The t-SNE and UMAP codes, which rely on TF-IDF Vectorization, are also interactive. They allow you to look at clustering behavior of the review documents for all of the label remapping schemes, for different ngram ranges, and for lemmatized vs. non-lemmatized tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "from yellowbrick.text import UMAPVisualizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_freq_dist(price_range=['1$', '2$', '3$', '4$', 'All Price Ranges'], token_num = (1,75)):\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "    tokenizer = dummy_fun,\n",
    "    preprocessor= dummy_fun,\n",
    "    token_pattern=None)\n",
    "    \n",
    "    price_range_dict = {'1$': '1', '2$': '2', '3$': '3', '4$': '4'}\n",
    "    if price_range != 'All Price Ranges':\n",
    "        docs = vectorizer.fit_transform(data[data['price_range'] == price_range_dict[price_range]]['review_tokens'])\n",
    "    else:\n",
    "        docs = vectorizer.fit_transform(data['review_tokens'])\n",
    "\n",
    "    features = vectorizer.get_feature_names()\n",
    "    visualizer = FreqDistVisualizer(features=features, size=(1080, 720), n=token_num, orient='h',\n",
    "                                   title='Frequency Distribution of Top {} Tokens for {}'.format(token_num,price_range))\n",
    "    visualizer.fit(docs)\n",
    "    visualizer.poof()\n",
    "    \n",
    "interact_manual(token_freq_dist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('figures/token_freq_distributions') if f.split('.')[1] == 'png']\n",
    "@interact\n",
    "def show_token_distrib(file=files):\n",
    "    display(Image(os.path.join('figures/token_freq_distributions/', file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdowns_dict={'Remap Price Range Only':['Default', '[1$ & 2$] vs. [3$ & 4$]', '[1$ & $2] vs [$4]'], \n",
    "           'Remap Price Range with Review Stars':['[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]', \n",
    "                                                  '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]']}\n",
    "\n",
    "remap_widget = widgets.Dropdown(options = dropdowns_dict.keys())\n",
    "scheme_widget = widgets.Dropdown()\n",
    "tokens_widget = widgets.Dropdown(options = ['Non-Lemmatized', 'Lemmatized'])\n",
    "ngram_widget = widgets.IntSlider(min=1, max=5)\n",
    "n_widget = widgets.IntSlider(min=500, max=20000, step=500)\n",
    "vis_widget = widgets.Dropdown(options=['t-SNE', 'UMAP'])\n",
    "\n",
    "def update(*args):\n",
    "    scheme_widget.options = dropdowns_dict[remap_widget.value]\n",
    "remap_widget.observe(update)\n",
    "\n",
    "def remap_labels(remap_type, scheme, tokens_type, ngram_range, n_documents, visualization):\n",
    "    def remap(remap_dict, value):\n",
    "        return remap_dict.get(value, None)\n",
    "\n",
    "    if 'remapped_labels' in data.columns:\n",
    "        data.drop(columns=['remapped_labels'], inplace=True)\n",
    "     \n",
    "    if remap_type == 'Remap Price Range Only':\n",
    "        \n",
    "        if scheme == 'Default':\n",
    "            data['remapped_labels'] = data['price_range']\n",
    "            title = '{} Projection of {} Reviews\\n(all price ranges)\\n(ngram range: 1 - {})'.format(visualization, n_documents, ngram_range)\n",
    "        \n",
    "        elif scheme == '[1$ & 2$] vs. [3$ & 4$]':\n",
    "            remap_dict = {'1':'1', '2':'1', '3':'2', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            title = '{} Projection of {} Reviews\\n([1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$])'.format(visualization, n_documents)\n",
    "            \n",
    "        else:\n",
    "            remap_dict = {'1':'1', '2':'1', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            title = '{} Projection of {} Reviews\\n([1\\\\$ & 2\\\\$] vs. [4\\\\$])'.format(visualization, n_documents)\n",
    "            \n",
    "    else:\n",
    "        if scheme == '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                     (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                     (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                     (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                     (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'  \n",
    "            title = '{} Projection of {} Reviews\\n([1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$] > [1*-3* & 4*-5*])'.format(visualization, n_documents)\n",
    "  \n",
    "        else:\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                     (data['review_stars'].isin([1,2])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                     (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                     (data['review_stars'].isin([1,2])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                     (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "            title = '{} Projection of {} Reviews\\n([1\\\\$ & 2\\\\$] vs. [3\\\\$ & 4\\\\$] > [1*-2* & 4*-5*])'.format(visualization, n_documents)\n",
    "    \n",
    "    remapped_data = data[data['remapped_labels'].notnull()]\n",
    "    remapped_data_sample = remapped_data.sample(n=n_documents)\n",
    "    target = remapped_data_sample['remapped_labels']\n",
    "    tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,\n",
    "                            token_pattern=None, ngram_range = (1,ngram_range), min_df=10)\n",
    "    if tokens_type == 'Non-Lemmatized':\n",
    "        tokens = 'review_tokens'\n",
    "    else:\n",
    "        tokens = 'lemmatized_tokens'\n",
    "    X = tfidf.fit_transform(remapped_data_sample[tokens])\n",
    "    \n",
    "    if visualization == 't-SNE':\n",
    "        tsne = TSNEVisualizer(colormap='viridis', title=title)\n",
    "        tsne.fit(X, target)\n",
    "        tsne.poof();\n",
    "    else:\n",
    "        umap = UMAPVisualizer(colormap='viridis', title=title)\n",
    "        umap.fit(X, target)\n",
    "        umap.poof();\n",
    "        \n",
    "widgets.interact_manual(remap_labels, remap_type=remap_widget, scheme=scheme_widget, tokens_type=tokens_widget,\n",
    "                        ngram_range=ngram_widget, n_documents=n_widget, visualization=vis_widget);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('figures/tsne_umap') if f.split('.')[1] == 'png']\n",
    "@interact\n",
    "def show_tsne_umaps(file=files):\n",
    "    display(Image(os.path.join('figures/tsne_umap/', file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Code in this section is highly interactive, with numerous widgets to facilitate the process of exploring different models. Specifically, in the initial block of modeling-related code, there are many options for steering model exploration. You can choose how you would like to remap the class labels, the size of the random sample you would like to take of the original dataset for model exploration, and the size of the test set (default is 0.2). You can also select the type of tokens to feed into the model &mdash; non-lemmatized or lemmatized &mdash; along with the vectorizer to use &mdash; ```CountVectorizer``` or ```TfidfVectorizer``` &mdash; and the vectorizer's ngram range.\n",
    "\n",
    "You can dictate, in addition to the vectorized text, what features you'd like to include &mdash; the counts of tokens in the reviews and/or the star ratings of the reviews. The latter of these features, star ratings, is only available for inclusion if the class label remapping scheme does not depend on price range AND star ratings. This mixing of heterogeneous features is made possible thanks to scikit-learn's ```FeatureUnion```. The code makes 9 classifiers available for comparison (you can select any combination of these models to compare, from one to all). However, you can easily add models by modifying the ```models_dict``` dictionary in the code. \n",
    "\n",
    "Finally, there are two widgets that give you control over the ```class_weight``` attribute in the models for which this attribute exists. Adjusting the value of this attribute &mdash; from 'auto' to 'balanced' to 'custom' &mdash; can significantly improve model performance, especially in the context of imbalanced data (which certainly applies to the dataset at hand). If 'custom' is selected, you can input your own class-weighting scheme to be used by the model(s). See the [scikit-learn documentation on ```class_weight```](https://scikit-learn.org/dev/glossary.html#term-class-weight) for more information on how to approach this attribute and how class weights will be used differently depending on the algorithm.\n",
    "\n",
    "For each model pipeline run, the code will let you know how long it took to fit the pipeline to the training data, and it will provide you with both a ```classification_report``` and ```confusion_matrix```. These two model performance summaries were chosen for the richness of the information they provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['is_restaurant'] == 1]\n",
    "data = data[data['tokens_len'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path, 'final_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path, 'final_data.pkl'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropdowns_dict={'Remap Price Range Only':['Default', '[1$ & 2$] vs. [3$ & 4$]', '[1$ & $2] vs [$4]'], \n",
    "               'Remap Price Range with Review Stars':['[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]', \n",
    "                                                      '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]']}\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "remap_widget = widgets.Dropdown(options = dropdowns_dict.keys(), description='Remap type:', \n",
    "                                style=style, value='Remap Price Range Only')\n",
    "scheme_widget = widgets.Dropdown(description='Scheme:')\n",
    "include_stars_widget = widgets.Dropdown(description='Include Star Ratings?:', style=style)\n",
    "\n",
    "def update(*args):\n",
    "    scheme_widget.options = dropdowns_dict[remap_widget.value]\n",
    "    if remap_widget.value == 'Remap Price Range Only':\n",
    "        include_stars_widget.options = ['Yes', 'No']\n",
    "    else:\n",
    "        include_stars_widget.options = ['No']\n",
    "remap_widget.observe(update)\n",
    "\n",
    "data_sample_size = widgets.BoundedFloatText(\n",
    "    value=0.2,\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.05,\n",
    "    description='Sample size:',\n",
    "    disabled=False)\n",
    "\n",
    "test_size = widgets.BoundedFloatText(\n",
    "    value=0.2,\n",
    "    min=0,\n",
    "    max=0.5,\n",
    "    step=0.05,\n",
    "    description='Test size:',\n",
    "    disabled=False)\n",
    "\n",
    "tokens_widget = widgets.RadioButtons(\n",
    "    options=['Non-Lemmatized', 'Lemmatized'],\n",
    "    description='Token type:',\n",
    "    disabled=False)\n",
    "\n",
    "vect_widget = widgets.ToggleButtons(\n",
    "    options=['TfidfVectorizer', 'CountVectorizer'],\n",
    "    description='Vectorizer:', style=style)\n",
    "\n",
    "tokens_len_widget = widgets.RadioButtons(\n",
    "    options=['Yes', 'No'],\n",
    "    description='Include Tokens Count?:',\n",
    "    style=style)\n",
    "\n",
    "ngram_widget = widgets.IntRangeSlider(min=1, max=5, description='Ngram range:', style=style)\n",
    "\n",
    "features_widget = widgets.SelectMultiple(\n",
    "    options=['TfidfVectorizer', 'CountVectorizer', 'Review Tokens Count'],\n",
    "    description='Features:',\n",
    "    disabled=False)\n",
    "\n",
    "models_dict = {'Logistic Regression':LogisticRegression(solver='lbfgs'), 'SGDClassifier':SGDClassifier(),\n",
    "               'SVC':SVC(gamma='auto'), 'NuSVC':NuSVC(gamma='auto'), 'LinearSVC':LinearSVC(),\n",
    "               'KNeighborsClassifier':KNeighborsClassifier(), 'BaggingClassifier':BaggingClassifier(),\n",
    "               'ExtraTreesClassifier':ExtraTreesClassifier(n_estimators=100), \n",
    "               'RandomForestClassifier':RandomForestClassifier(n_estimators=100)}\n",
    "\n",
    "models = widgets.SelectMultiple(\n",
    "    options=models_dict.keys(),\n",
    "    description='Models',\n",
    "    disabled=False)\n",
    "\n",
    "class_weight_widget = widgets.ToggleButtons(options=['auto', 'balanced', 'custom'], \n",
    "                                            description='Models class_weight:', \n",
    "                                            style=style, value='auto')\n",
    "\n",
    "custom_weight_widget = widgets.Text(disabled=True, description='Custom weight scheme:', style=style,\n",
    "                                    placeholder='N/A')\n",
    "\n",
    "def update2(*args):\n",
    "    if class_weight_widget.value == 'custom':\n",
    "        custom_weight_widget.placeholder='{class_label: weight}'\n",
    "        custom_weight_widget.disabled = False\n",
    "    else:\n",
    "        custom_weight_widget.placeholder='N/A'\n",
    "        custom_weight_widget.disabled = True\n",
    "class_weight_widget.observe(update2)\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]\n",
    "\n",
    "def remap(remap_dict, value):\n",
    "    return remap_dict.get(value, None)\n",
    "\n",
    "def compare_models(remap_type, scheme, tokens_type, sample_frac, test_frac, \n",
    "                   vectorizer, ngram_range, include_tokens_len, include_stars, \n",
    "                   classifiers, class_weight, custom_weight):\n",
    "    \n",
    "    if class_weight == 'custom':\n",
    "        try:\n",
    "            custom_weight = yaml.load(custom_weight)\n",
    "            if isinstance(custom_weight, dict) == False:\n",
    "                raise ValueError('Please enter custom_weight in the following format: {class_label1: weight1, class_label2: weight2, etc.}')\n",
    "\n",
    "        except:\n",
    "            raise ValueError('Please enter custom_weight in the following format: {class_label1: weight1, class_label2: weight2, etc.}')\n",
    "\n",
    "    if 'remapped_labels' in data.columns:\n",
    "        data.drop(columns=['remapped_labels'], inplace=True)\n",
    "       \n",
    "    if remap_type == 'Remap Price Range Only':\n",
    "        \n",
    "        if scheme == 'Default':\n",
    "            data['remapped_labels'] = data['price_range']\n",
    "            target_names = ['1$', '2$', '3$', '4$']\n",
    "        \n",
    "        elif scheme == '[1$ & 2$] vs. [3$ & 4$]':\n",
    "            remap_dict = {'1':'1', '2':'1', '3':'2', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            target_names = ['[1$ & 2$]', '[3$ & 4$]']\n",
    "            \n",
    "        else:\n",
    "            remap_dict = {'1':'1', '2':'1', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            target_names = ['[1$ & 2$]', '[$4]']\n",
    "    else:\n",
    "        if scheme == '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "            target_names = ['[1$ & 2$] > [1*-3*]', '[1$ & 2$] > [4*-5*]', \n",
    "                            '[3$ & 4$] > [1*-3*]', '[3$ & 4$] > [4*-5*]']\n",
    "  \n",
    "        else:\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([1,2])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([1,2])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "            target_names = ['[1$ & 2$] > [1*-2*]', '[1$ & 2$] > [4*-5*]', \n",
    "                            '[3$ & 4$] > [1*-2*]', '[3$ & 4$] > [4*-5*]']\n",
    "            \n",
    "    remapped_data = data[data['remapped_labels'].notnull()]\n",
    "    \n",
    "    if class_weight == 'custom':\n",
    "        if set(remapped_data['remapped_labels'].unique()) != set(custom_weight.keys()):\n",
    "            raise ValueError('Please enter custom_weight in the following format: {class_label1: weight1, class_label2: weight2, etc.}\\nMake sure the key-value pairs only include all class labels and their weights.')\n",
    "    \n",
    "    remapped_data_sample = remapped_data.sample(frac=sample_frac)\n",
    "    \n",
    "    if tokens_type == 'Non-Lemmatized':\n",
    "        tokens = 'review_tokens'\n",
    "    else:\n",
    "        tokens = 'lemmatized_tokens'\n",
    "        \n",
    "\n",
    "    if include_tokens_len == 'Yes' and include_stars == 'Yes':\n",
    "        features = [tokens, 'tokens_len', 'review_stars']\n",
    "        \n",
    "    elif include_tokens_len == 'Yes' and include_stars == 'No':\n",
    "        features = [tokens, 'tokens_len']\n",
    "    \n",
    "    elif include_tokens_len == 'No' and include_stars == 'Yes':\n",
    "        features = [tokens, 'review_stars']\n",
    "    \n",
    "    else:\n",
    "        features = [tokens]\n",
    " \n",
    "    X = remapped_data_sample[features]\n",
    "\n",
    "    y = remapped_data_sample['remapped_labels']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_frac, stratify=y)\n",
    "\n",
    "    for clf in classifiers:\n",
    "        model = models_dict[clf]\n",
    "        \n",
    "        if hasattr(model, 'class_weight'):\n",
    "            if class_weight != 'custom':\n",
    "                model.class_weight = class_weight\n",
    "            else:\n",
    "                model.class_weight = custom_weight\n",
    "            \n",
    "        else:\n",
    "            print('{} does not have class_weight attribute. Cannot set to {}\\n.'.format(model.__class__.__name__, class_weight))\n",
    "            \n",
    "        if vectorizer == 'CountVectorizer':\n",
    "            vect_step = ('vect', CountVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,\n",
    "                                            token_pattern=None, ngram_range=ngram_range))\n",
    "        else:\n",
    "            vect_step = ('vect', TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,\n",
    "                                            token_pattern=None, ngram_range=ngram_range))\n",
    "\n",
    "        text = Pipeline([\n",
    "                        ('selector', TextSelector(tokens)),\n",
    "                        vect_step\n",
    "                        ])\n",
    "\n",
    "        stars = Pipeline([('selector', NumberSelector('review_stars'))])\n",
    "\n",
    "        tokens_count = Pipeline([\n",
    "                                ('selector', NumberSelector('tokens_len')),\n",
    "                                ('standard', StandardScaler())\n",
    "                                ])\n",
    "\n",
    "        if include_tokens_len == 'No':\n",
    "            if include_stars == 'No':\n",
    "                feats = text\n",
    "            else:\n",
    "                feats = FeatureUnion([('text', text),\n",
    "                                      ('stars', stars)])\n",
    "\n",
    "        else:\n",
    "            if include_stars == 'No':\n",
    "                feats = FeatureUnion([('text', text),\n",
    "                                      ('tokens_count', tokens_count)])\n",
    "            else:\n",
    "                feats = FeatureUnion([('text', text),\n",
    "                                      ('tokens_count', tokens_count),\n",
    "                                      ('stars', stars)])        \n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('features', feats),\n",
    "            ('clf', model),\n",
    "        ])\n",
    "\n",
    "        print(pipeline.steps)\n",
    "            \n",
    "        print('Fitting {} pipeline --- '.format(model.__class__.__name__), end='')\n",
    "        time_start = time.time()\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        time_stop = time.time()\n",
    "        elapsed = time_stop - time_start\n",
    "        print('{} minutes {} seconds'.format(elapsed // 60, elapsed % 60))\n",
    "        print('\\n')\n",
    "        print(classification_report(y_test, preds, target_names=target_names))\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        print('\\n')\n",
    "\n",
    "interact_manual(compare_models, remap_type=remap_widget, scheme=scheme_widget, \n",
    "                tokens_type=tokens_widget, sample_frac=data_sample_size, test_frac=test_size,\n",
    "                vectorizer=vect_widget, ngram_range=ngram_widget, include_tokens_len=tokens_len_widget, \n",
    "                include_stars=include_stars_widget, classifiers=models, class_weight=class_weight_widget,\n",
    "                custom_weight=custom_weight_widget);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Observations &mdash; Imbalanced Dataset\n",
    "\n",
    "From running several iterations of different model pipelines above, it is immediately clear that the imbalanced natures of the datasets (both the original with the default price range class labels and the remapped ones) are confounding model performance. While adjusting the ```class_weight``` attributes for certain models to 'balanced' or customized schemes markedly improves classification performance (particularly reflected through recall scores) on minority classes, the models are still generally performing poorly on the minority classes. \n",
    "\n",
    "#### Possible Approaches to Handling the Imbalance\n",
    "\n",
    "There are myriad approaches for dealing with imbalanced data, as this is a common phenomenon within machine learning problems. This notebook will explore some of these methods using the library [```imbalanced-learn (imblearn)```](https://imbalanced-learn.readthedocs.io/en/stable/index.html), which \"is a Python package offering a number of re-sampling techniques commonly used in datasets showing strong between-class imbalance.\" \n",
    "\n",
    "Specifically, this notebook looks at the following oversampling techniques of the minority classes:\n",
    "- [```RandomOverSampler```](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#random-over-sampler):  This technique \"generate[s] new samples in the classes which are under-represented. The most naive strategy is to generate new samples by randomly sampling with replacement the current available samples.\" Therefore, synthetic data is not created, as the technique duplicates observations from the minority class(es).\n",
    "- [```ADASYN```](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn): This technique over-samples the minority class(es) by generating \"new samples in by interpolation.\" ```ADASYN``` \"focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier.\"\n",
    "- [```SMOTE```](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn): This technique also, like ```ADASYN```, creates synthetic data. \"The basic implementation of ```SMOTE``` will not make any distinction between easy and hard samples to be classified using the nearest neighbors rule.\"\n",
    "\n",
    "The interactive code below allows you to compare model performances across these different oversampling techniques. Like the interactive code before, you can specify the sample size of the dataset you want to work with, the class label remapping strategy, the vectorization method and ngram range, the combination of classifier(s) to compare, and the combination of oversampling method(s) to compare. Note that the widget for selecting a combination of oversampling techniques also inclues a sampler called 'Standard/Default'. This sampler is a dummy sampler that simply returns the data as is; it is included as an option for facilitating comparison between oversampling methods and the default data. New to this section's interactive code, however, is the option to use cross-validation when comparing across the different oversampling techniques. You can specify whether or not you want to use the ```Stratified K-Folds cross-validator``` from scikit-learn and how many splits to use. If you opt not to use cross-validation, you can specify the size of the test size you want to use when calling ```train_test_split```.\n",
    "\n",
    "When cross-validation is not selected, the code will return the [```classification_report_imbalanced```](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.metrics.classification_report_imbalanced.html) summary from ```imblearn``` for each fitted pipeline. When cross-validation is selected, the code will return performance stats for each fold, and when all folds are complete, summary stats for all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropdowns_dict={'Remap Price Range Only':['Default', '[1$ & 2$] vs. [3$ & 4$]', '[1$ & $2] vs [$4]'], \n",
    "               'Remap Price Range with Review Stars':['[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]', \n",
    "                                                      '[1$ & 2$] vs. [3$ & 4$] > [1*-2* & 4*-5*]']}\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "remap_widget = widgets.Dropdown(options = dropdowns_dict.keys(), description='Remap type:', \n",
    "                                style=style, value='Remap Price Range Only')\n",
    "scheme_widget = widgets.Dropdown(description='Scheme:')\n",
    "\n",
    "def update(*args):\n",
    "    scheme_widget.options = dropdowns_dict[remap_widget.value]\n",
    "remap_widget.observe(update)\n",
    "\n",
    "data_sample_size = widgets.BoundedFloatText(\n",
    "    value=0.2,\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.05,\n",
    "    description='Sample size:',\n",
    "    disabled=False)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "models_dict = {'Logistic Regression':LogisticRegression(solver='lbfgs'), 'SGDClassifier':SGDClassifier(),\n",
    "               'SVC':SVC(gamma='auto'), 'NuSVC':NuSVC(gamma='auto'), 'LinearSVC':LinearSVC(),\n",
    "               'KNeighborsClassifier':KNeighborsClassifier(), 'BaggingClassifier':BaggingClassifier(),\n",
    "               'ExtraTreesClassifier':ExtraTreesClassifier(n_estimators=100), \n",
    "               'RandomForestClassifier':RandomForestClassifier(n_estimators=100)}\n",
    "\n",
    "class DummySampler:\n",
    "    def sample(self, X, y):\n",
    "        return X, y\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def fit_resample(self, X, y):\n",
    "        return self.sample(X, y)\n",
    "\n",
    "samplers_dict = {'Standard/Default': DummySampler(), 'ADASYN': ADASYN(random_state=RANDOM_STATE),\n",
    "                 'RandomOverSampler': RandomOverSampler(random_state=RANDOM_STATE),\n",
    "                 'SMOTE': SMOTE(random_state=RANDOM_STATE)}\n",
    "\n",
    "models = widgets.SelectMultiple(\n",
    "    options=models_dict.keys(),\n",
    "    description='Models',\n",
    "    disabled=False)\n",
    "\n",
    "samplers_widget = widgets.SelectMultiple(\n",
    "    options=samplers_dict.keys(),\n",
    "    description='Oversampling method:',\n",
    "    style=style)\n",
    "\n",
    "vect_widget = widgets.ToggleButtons(\n",
    "    options=['CountVectorizer', 'TfidfVectorizer'],\n",
    "    description='Vectorizer:', style=style)\n",
    "\n",
    "ngram_widget = widgets.IntRangeSlider(min=1, max=5, description='Ngram range:', style=style)\n",
    "\n",
    "cv_widget = widgets.Dropdown(options=['Yes', 'No'], description='Use cross-validation?:', style=style)\n",
    "\n",
    "test_size = widgets.BoundedFloatText(disabled=True, description='Test size:', style=style,\n",
    "                                    placeholder='N/A')\n",
    "splits_widget = widgets.IntSlider(min=2, max=12, description='Number of splits:', style=style,\n",
    "                                       disabled=False)\n",
    "\n",
    "def update2(*args):\n",
    "    if cv_widget.value == 'No':\n",
    "        test_size.disabled = False\n",
    "        test_size.value=0.2\n",
    "        test_size.min=0\n",
    "        test_size.max=0.5\n",
    "        test_size.step=0.05\n",
    "        splits_widget.disabled = True\n",
    "    else:\n",
    "        splits_widget.disabled=False\n",
    "        test_size.disabled = True\n",
    "cv_widget.observe(update2)\n",
    "    \n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "    \n",
    "def remap(remap_dict, value):\n",
    "    return remap_dict.get(value, None)\n",
    "\n",
    "def compare_oversampling_methods(remap_type, scheme, sample_frac, vectorizer, \n",
    "                                 ngram_range, classifiers, samplers, \n",
    "                                 use_cv, n_splits, test_frac):\n",
    "\n",
    "    if 'remapped_labels' in data.columns:\n",
    "        data.drop(columns=['remapped_labels'], inplace=True)\n",
    "       \n",
    "    if remap_type == 'Remap Price Range Only':\n",
    "        \n",
    "        if scheme == 'Default':\n",
    "            data['remapped_labels'] = data['price_range']\n",
    "            target_names = ['1$', '2$', '3$', '4$']\n",
    "        \n",
    "        elif scheme == '[1$ & 2$] vs. [3$ & 4$]':\n",
    "            remap_dict = {'1':'1', '2':'1', '3':'2', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            target_names = ['[1$ & 2$]', '[3$ & 4$]']\n",
    "            \n",
    "        else:\n",
    "            remap_dict = {'1':'1', '2':'1', '4':'2'}\n",
    "            data['remapped_labels'] = data['price_range'].apply(lambda x: remap(remap_dict, x))\n",
    "            target_names = ['[1$ & 2$]', '[$4]']\n",
    "    else:\n",
    "        if scheme == '[1$ & 2$] vs. [3$ & 4$] > [1*-3* & 4*-5*]':\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([1,2,3])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "            target_names = ['[1$ & 2$] > [1*-3*]', '[1$ & 2$] > [4*-5*]', \n",
    "                            '[3$ & 4$] > [1*-3*]', '[3$ & 4$] > [4*-5*]']\n",
    "  \n",
    "        else:\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([1,2])), 'remapped_labels'] = '1'\n",
    "            data.loc[(data['price_range'].isin(['1','2'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '2'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([1,2])), 'remapped_labels'] = '3'\n",
    "            data.loc[(data['price_range'].isin(['3','4'])) &\n",
    "                             (data['review_stars'].isin([4,5])), 'remapped_labels'] = '4'\n",
    "            target_names = ['[1$ & 2$] > [1*-2*]', '[1$ & 2$] > [4*-5*]', \n",
    "                            '[3$ & 4$] > [1*-2*]', '[3$ & 4$] > [4*-5*]']\n",
    "            \n",
    "    remapped_data = data[data['remapped_labels'].notnull()]   \n",
    "    remapped_data_sample = remapped_data.sample(frac=sample_frac)\n",
    "    #remapped_data_sample['review_tokens'] = remapped_data_sample['review_tokens'].apply(lambda x: ' '.join(x))\n",
    "    X = remapped_data_sample['review_tokens']\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y = remapped_data_sample['remapped_labels']\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    vectorizer_dict = {'CountVectorizer':CountVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,\n",
    "                                            token_pattern=None, ngram_range=ngram_range),\n",
    "                   'TfidfVectorizer':TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun,\n",
    "                                            token_pattern=None, ngram_range=ngram_range)}\n",
    "\n",
    "    pipelines = [\n",
    "        ['{}-{}-{}'.format(vectorizer, sampler, clf),\n",
    "         make_pipeline(vectorizer_dict[vectorizer], samplers_dict[sampler], models_dict[clf])]\n",
    "        for sampler in samplers for clf in classifiers\n",
    "    ]\n",
    "\n",
    "    for name, pipeline in pipelines:\n",
    "        #print(pipeline.steps)\n",
    "        if use_cv == 'No':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_frac, stratify=y)\n",
    "            print('Fitting {} pipeline --- '.format(name), end='')\n",
    "            time_start = time.time()\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            preds = pipeline.predict(X_test)\n",
    "            time_stop = time.time()\n",
    "            elapsed = time_stop - time_start\n",
    "            print('{} minutes {} seconds'.format(elapsed // 60, elapsed % 60))\n",
    "            print('\\n')\n",
    "            print(classification_report_imbalanced(y_test, preds, target_names=target_names))\n",
    "        \n",
    "        else:\n",
    "            #print('X: {}'.format(X))\n",
    "            kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=777)\n",
    "            accuracy = []\n",
    "            precision = []\n",
    "            recall = []\n",
    "            f1 = []\n",
    "            fold = 0\n",
    "            for train, test in kfold.split(X, y):\n",
    "                fold += 1\n",
    "                print('Fitting {} pipeline for fold {}/{} --- '.format(name, fold, n_splits), end='')\n",
    "                time_start = time.time()\n",
    "                pipeline.fit(X[train], y[train])\n",
    "                preds = pipeline.predict(X[test])\n",
    "                time_stop = time.time()\n",
    "                elapsed = time_stop - time_start\n",
    "                print('{} minutes {} seconds'.format(elapsed // 60, elapsed % 60))\n",
    "                scores = pipeline.score(X[test], y[test])\n",
    "                accuracy.append(scores * 100)\n",
    "                precision.append(precision_score(y[test], preds, average='macro')*100)\n",
    "                print('\\n')\n",
    "                print('precision: {}'.format(precision_score(y[test], preds, average=None)))\n",
    "                recall.append(recall_score(y[test], preds, average='macro')*100)\n",
    "                print('recall: {}'.format(recall_score(y[test], preds, average=None)))\n",
    "                f1.append(f1_score(y[test], preds, average='macro')*100)\n",
    "                print('f1 score: {}'.format(f1_score(y[test], preds, average=None)))\n",
    "                print('\\n')\n",
    "            print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "            print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "            print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "            print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))\n",
    "            print('\\n')\n",
    "\n",
    "interact_manual(compare_oversampling_methods, remap_type=remap_widget, scheme=scheme_widget,\n",
    "                sample_frac=data_sample_size, vectorizer=vect_widget,\n",
    "                ngram_range=ngram_widget, classifiers=models, samplers=samplers_widget,\n",
    "                use_cv=cv_widget, n_splits=splits_widget, test_frac=test_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "The ideal way to \"fix\" imbalanced data is collecting more minority class observations, not generating synthetic ones or undersampling (oversampling) the majority class(es) (minority class(es)). Unfortunately, for many machine learning problems, the ability to collect more data points can be nearly impossible, onerous (resource-wise, time-wise, etc.), or tricky. For example, a government may only publish X observations every 5 years. How would you go about supplementing this data if it's heavily imbalanced? Take another example of a dataset with tweets, some annotated as abusive, others annotated as neutral. This dataset is likely heavily imbalanced in favor of neutral tweets. You could technically use the Twitter API to collect more tweets, but that then begs the question... how are you going to ensure that this additional data has the supplemental abusive tweets you need? Sure, you can use custom API queries to try to tease out tweets that are more likely abusive in nature, but certain queries may bias what abusive content you are pulling (e.g., by using pre-determined abusive terms, you may be missing out on tweets that are more subtly abusive).\n",
    "\n",
    "Yelp data, however, is a bit of an exception. Yelp offers [Fusion APIs](https://www.yelp.com/fusion) through which business and review data can be collected. When making a call to the API, you can request results having specific price range values! You could then plug the business_ids returned from that call to receive up to 3 reviews per business. This doesn't guarantee that the returned reviews will have the desired star ratings (if using a class relabeling scheme that takes into account both price range and review star rating), but you could make multiple calls to the API and then filter out reviews that don't meet the required conditions. There is a potential worry that the distribution of results from the APIs differs from that of the Yelp dataset at hand, but using the APIs to supplement the dataset is one way to add real, fresh observations to the minority classes.\n",
    "\n",
    "Due to time constraints, this notebook did not explore the Yelp APIs avenue for bolstering the representation of minority classes in the dataset, but this will be the next step. It will be interesting to compare model performances on this dataset supplemented with actual, fresh Yelp reviews with those using the aforementioned oversampling techniques. \n",
    "\n",
    "It will also be interesting in the future to engineer new text-based features &mdash; like POS tags or frequency counts of words from informal/formal lexicons (as a proxy for the formality of language being used) &mdash; and to home in on one model and conduct hyperparameter tuning (perhaps with ```GridSearchCV```)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
